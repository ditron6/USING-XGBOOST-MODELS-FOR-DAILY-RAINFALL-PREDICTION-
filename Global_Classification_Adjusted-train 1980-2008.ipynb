{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "<h1><center> UFU - Federal University of Uberlândia</center></h1>\n",
                "\n",
                "<h2><center>Undergraduate Program in Civil Engineering</center></h2>\n",
                "\n",
                "<h3><center>SCIENTIFIC RESEARCH PROJECT</center><br>\n",
                "TITLE: USING XGBOOST MODELS FOR DAILY RAINFALL PREDICTION \n",
                "<br>  \n",
                "<br>  \n",
                "STUDENT: Pedro Augusto Toledo Rios</h3>\n",
                "\n",
                "<p>This notebook is part of a Scientific Research Project in the field of Computer Science/Data Analysis.</p>\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Classification\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Imports and Initial Configurations\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Data analysis and preprocessing\n",
                "import pandas as pd  # Data manipulation and analysis\n",
                "import numpy as np  # Numerical computations\n",
                "import random as rnd  # Random number generation\n",
                "import seaborn as sn  # Data visualization\n",
                "\n",
                "# Visualization libraries\n",
                "import seaborn as sns  # Statistical data visualization\n",
                "import matplotlib.pyplot as plt  # General plotting\n",
                "%matplotlib inline  \n",
                "\n",
                "# Machine learning models\n",
                "from sklearn.linear_model import LogisticRegression  # Logistic regression model\n",
                "from sklearn.svm import SVC, LinearSVC  # Support Vector Classifier (SVC)\n",
                "from sklearn.ensemble import RandomForestClassifier  # Random Forest classifier\n",
                "from sklearn.neighbors import KNeighborsClassifier  # K-Nearest Neighbors (KNN)\n",
                "from sklearn.naive_bayes import GaussianNB  # Naive Bayes classifier\n",
                "from sklearn.linear_model import Perceptron  # Perceptron classifier\n",
                "from sklearn.linear_model import SGDClassifier  # Stochastic Gradient Descent classifier\n",
                "from sklearn.tree import DecisionTreeClassifier  # Decision Tree classifier\n",
                "from sklearn.model_selection import train_test_split  # Data splitting for training/testing\n",
                "from sklearn.linear_model import LinearRegression  # Linear regression model\n",
                "from sklearn import metrics  # Evaluation metrics\n",
                "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score  # Classification metrics\n",
                "from sklearn.metrics import classification_report, confusion_matrix  # Model evaluation tools\n",
                "import itertools  # Itertools for handling iterators\n",
                "from sklearn import svm  # Support Vector Machines\n",
                "from sklearn.naive_bayes import GaussianNB  # Gaussian Naive Bayes (repeated import)\n",
                "from sklearn.ensemble import AdaBoostClassifier  # AdaBoost classifier\n",
                "from sklearn.metrics import ConfusionMatrixDisplay  # Confusion matrix visualization\n",
                "\n",
                "# Gradient boosting models\n",
                "import xgboost as xgb  # XGBoost classifier\n",
                "import lightgbm as lgb  # LightGBM classifier\n",
                "\n",
                "# Logistic regression (repeated import)\n",
                "from sklearn.linear_model import LogisticRegression\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Exploratory Data Analysis\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd  # Library for data manipulation\n",
                "\n",
                "# List of invalid values to be treated as NaN (missing values)\n",
                "missing_values = [\n",
                "    'n/a', 'na', '*****', '*', '*******', ' -', '******', '5..84', '3..66', '3.3.21', \n",
                "    '1..41', '********', '3.7.94', '354.59*', '564..79', '5.04.24', '21:36', '**********', \n",
                "    '***', '*********', '03:18', '00:00', '03:48', '08:42', '03:06', '09:06', '01:30', \n",
                "    '07:48', '09:12', '10:18', '01:24', '#VALUE!', '926,4923,8', '27/07/1902**21:36:00', \n",
                "    '-', '926.4923.8', '185.488.992', '4.535.416.667', '3.495.833.333', '2.015.833.333', \n",
                "    '2.489.166.667', '4.745.416.667', '3.227.916.667', '3.594.166.667', '3.720.416.667', \n",
                "    '06:12', '04:36', '06:48'\n",
                "]\n",
                "\n",
                "# Load the dataset from CSV file\n",
                "weather_data = pd.read_csv(\n",
                "    'C:/Users/auped/Desktop/IC CORREÇÕES/python 05-11/pesquisa/dadosclimaatt - CORRETO.csv', \n",
                "    header=None, sep=';', na_values=missing_values\n",
                ")\n",
                "\n",
                "# Rename columns for better readability\n",
                "weather_data.columns = [\n",
                "    'Max Temperature (°C)', 'Min Temperature (°C)', 'Avg Temperature (°C)', 'Wind Speed (m/s)', \n",
                "    'Solar Radiation (cal/cm²/h)', 'Pressure (mb)', 'Relative Humidity (%)', 'Daily Rainfall (mm)', \n",
                "    'Month', 'Year'\n",
                "]\n",
                "\n",
                "# Data cleaning and type conversion\n",
                "weather_data['Pressure (mb)'] = weather_data['Pressure (mb)'].astype(str).str.replace(',,', '')\n",
                "weather_data['Pressure (mb)'] = pd.to_numeric(weather_data['Pressure (mb)'], errors='coerce')\n",
                "\n",
                "weather_data['Relative Humidity (%)'] = pd.to_numeric(weather_data['Relative Humidity (%)'], errors='coerce')\n",
                "\n",
                "weather_data['Year'] = weather_data['Year'].astype(str).str.replace(',,', '')\n",
                "weather_data['Year'] = pd.to_numeric(weather_data['Year'], errors='coerce').astype('Int64')\n",
                "\n",
                "# Convert wind speed from km/h to m/s\n",
                "weather_data['Wind Speed (m/s)'] = pd.to_numeric(weather_data['Wind Speed (m/s)'], errors='coerce') / 3.6  \n",
                "\n",
                "weather_data['Solar Radiation (cal/cm²/h)'] = pd.to_numeric(weather_data['Solar Radiation (cal/cm²/h)'], errors='coerce')\n",
                "\n",
                "# Filter pressure values within a valid range\n",
                "weather_data = weather_data[(weather_data['Pressure (mb)'] >= 870) & (weather_data['Pressure (mb)'] <= 1100)]\n",
                "\n",
                "# Remove rows with remaining NaN values\n",
                "weather_data.dropna(inplace=True)\n",
                "\n",
                "# Display the number of missing values in each column\n",
                "print(weather_data.isnull().sum())\n",
                "\n",
                "# Display the first five rows of the processed dataset\n",
                "print(weather_data.head())\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Information about each column in the DataFrame\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "weather_data.describe()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Creation of a new class to determine whether it rained on a given day\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create a new column 'Rained?' with 0 (no rain) and 1 (rain)\n",
                "weather_data['Rained?'] = (weather_data['Daily Rainfall (mm)'] > 0).astype(int)\n",
                "\n",
                "# Display the first five rows of the dataset\n",
                "print(weather_data.head())\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Handling Missing Values  \n",
                "weather_data['Min Temperature (°C)'].fillna(method='ffill', inplace=True)\n",
                "weather_data['Avg Temperature (°C)'].fillna(method='ffill', inplace=True)\n",
                "weather_data['Wind Speed (m/s)'].fillna(method='ffill', inplace=True)\n",
                "weather_data['Solar Radiation (cal/cm²/h)'].fillna(method='ffill', inplace=True)  # Corrected\n",
                "weather_data['Relative Humidity (%)'].fillna(method='ffill', inplace=True)\n",
                "weather_data['Daily Rainfall (mm)'].fillna(method='ffill', inplace=True)  # Corrected\n",
                "weather_data['Pressure (mb)'].fillna(method='ffill', inplace=True)\n",
                "weather_data['Rained?'].fillna(method='ffill', inplace=True)\n",
                "weather_data['Max Temperature (°C)'].fillna(method='ffill', inplace=True)\n",
                "\n",
                "# Check for missing values after imputation  \n",
                "print('\\nMissing Values in the dataframe after processing:\\n', weather_data.isnull().sum(), sep=\"\")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Compute Pearson correlation and sort the values\n",
                "columns_corr = weather_data.corr(method='pearson')['Rained?'].sort_values()\n",
                "print(columns_corr)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Code snippets to filter the DataFrame for a specific period of interest.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 70% for training / 30% for testing  \n",
                "\n",
                "start_year = 1980  \n",
                "end_year = 2020  \n",
                "train_start_year = 1980  \n",
                "train_end_year = 2008  \n",
                "test_start_year = 2009  \n",
                "test_end_year = 2019  \n",
                "\n",
                "# Create a copy of the dataset for testing  \n",
                "test_data = weather_data.copy()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "test_data.drop(columns=['Daily Rainfall (mm)'], axis=1, inplace=True)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Machine Learning Models\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Creating Training and Testing DataFrames\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create Training and Testing DataFrames  \n",
                "df_train = test_data[test_data['Year'] >= train_start_year]  \n",
                "df_train = test_data[test_data['Year'] <= train_end_year]  \n",
                "df_test = test_data[test_data['Year'] >= test_start_year]  \n",
                "df_test = test_data[test_data['Year'] <= test_end_year]  \n",
                "\n",
                "# Splitting features (X) and target variable (y)  \n",
                "x_train = df_train.iloc[:, 0:9]  \n",
                "y_train = df_train[['Rained?']]  \n",
                "\n",
                "x = df_test.iloc[:, 0:9]  \n",
                "y = df_test[['Rained?']]  \n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Model - XGBoost to Determine Whether It Rained or Not\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Creating the XGBoost classifier object  \n",
                "xgboost_model = xgb.XGBClassifier()  \n",
                "\n",
                "# Training the XGBoost classifier  \n",
                "trained_xgb_model = xgboost_model.fit(x, y)  \n",
                "\n",
                "# Testing the model  \n",
                "y_pred4 = trained_xgb_model.predict(x_train)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn import datasets\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.linear_model import LogisticRegression\n",
                "from sklearn.metrics import precision_recall_curve\n",
                "import matplotlib.pyplot as plt"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Score"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print('Precision: %.3f' % precision_score(y_train, y_pred4))\n",
                "print('Recall: %.3f' % recall_score(y_train, y_pred4))\n",
                "print('Accuracy: %.3f' % accuracy_score(y_train, y_pred4))\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "chuvaprevista = []\n",
                "for z in range(len(y_pred4)):\n",
                "    #print(y_pred4[z])\n",
                "    chuvaprevista.append(y_pred4[z])\n",
                "    \n",
                "df_train['Previsão']= chuvaprevista\n",
                "df_train.head()    "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from xgboost import plot_importance\n",
                "from matplotlib import pyplot  # Adicione esta linha de importação\n",
                "\n",
                "plot_importance(xgboost_model)\n",
                "pyplot.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Confusion Matrices\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Model - XGBoost\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Compute the confusion matrix  \n",
                "cm = confusion_matrix(y_train, y_pred4)  \n",
                "\n",
                "# Define class labels (replace with specific labels if necessary)  \n",
                "class_names = ['Negative Class', 'Positive Class']  \n",
                "\n",
                "# Plot the confusion matrix using Seaborn  \n",
                "plt.figure(figsize=(8, 6))  \n",
                "sns.set(font_scale=1.2)  # Adjust font size  \n",
                "\n",
                "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)  \n",
                "\n",
                "plt.xlabel('Predicted Label')  \n",
                "plt.ylabel('True Label')  \n",
                "plt.show()\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.9"
        },
        "orig_nbformat": 4
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
