{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "<h1><center> UFU - Federal University of Uberlândia</center></h1>\n",
                "\n",
                "<h2><center>Undergraduate Program in Civil Engineering</center></h2>\n",
                "\n",
                "<h3><center>SCIENTIFIC RESEARCH PROJECT</center><br>\n",
                "TITLE: USING XGBOOST MODELS FOR DAILY RAINFALL PREDICTION \n",
                "<br>  \n",
                "<br>  \n",
                "STUDENT: Pedro Augusto Toledo Rios</h3>\n",
                "\n",
                "<p>This notebook is part of a Scientific Research Project in the field of Computer Science/Data Analysis.</p>\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Classification"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Imports and Initial Configurations"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Data Analysis and Preprocessing\n",
                "import pandas as pd  # Library for data manipulation and analysis\n",
                "import numpy as np  # Library for numerical computing\n",
                "import random as rnd  # Library for generating random numbers\n",
                "import seaborn as sns  # Library for statistical data visualization\n",
                "\n",
                "# Data Visualization\n",
                "import matplotlib.pyplot as plt  # Library for creating static, animated, and interactive visualizations\n",
                "%matplotlib inline  \n",
                "\n",
                "# Machine Learning Libraries\n",
                "from sklearn.linear_model import LogisticRegression  # Logistic Regression model\n",
                "from sklearn.svm import SVC, LinearSVC  # Support Vector Machine (SVM) classifiers\n",
                "from sklearn.ensemble import RandomForestClassifier  # Random Forest classifier\n",
                "from sklearn.neighbors import KNeighborsClassifier  # k-Nearest Neighbors (k-NN) classifier\n",
                "from sklearn.naive_bayes import GaussianNB  # Gaussian Naïve Bayes classifier\n",
                "from sklearn.linear_model import Perceptron  # Perceptron classifier (basic neural network)\n",
                "from sklearn.linear_model import SGDClassifier  # Stochastic Gradient Descent classifier\n",
                "from sklearn.tree import DecisionTreeClassifier  # Decision Tree classifier\n",
                "from sklearn.model_selection import train_test_split  # Function to split data into training and testing sets\n",
                "from sklearn.linear_model import LinearRegression  # Linear Regression model\n",
                "from sklearn import metrics  # Evaluation metrics for model performance\n",
                "from sklearn.metrics import (precision_score, recall_score, f1_score, \n",
                "                             accuracy_score, classification_report, confusion_matrix)  # Various classification metrics\n",
                "import itertools  # Library for advanced iteration functions\n",
                "from sklearn import svm  # Support Vector Machine models\n",
                "from sklearn.ensemble import AdaBoostClassifier  # AdaBoost ensemble classifier\n",
                "from sklearn.metrics import ConfusionMatrixDisplay  # Tool for visualizing confusion matrices\n",
                "import xgboost as xgb  # Extreme Gradient Boosting (XGBoost) classifier\n",
                "import lightgbm as lgb  # Light Gradient Boosting Machine (LightGBM) classifier\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Exploratory Data Analysis"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Data Preprocessing and Cleaning\n",
                "\n",
                "# List of missing values to be identified and replaced with NaN\n",
                "missing_values = [\n",
                "    'n/a', 'na', '*****', '*', '*******', ' -', '******', \n",
                "    '5..84', '3..66', '3.3.21', '1..41', '********', '3.7.94', \n",
                "    '354.59*', '564..79', '5.04.24', '21:36', '**********', '***', \n",
                "    '*********', '03:18', '00:00', '03:48', '08:42', '03:06', \n",
                "    '09:06', '01:30', '07:48', '09:12', '10:18', '01:24', '#VALUE!',  \n",
                "    '926,4923,8', '27/07/1902**21:36:00', '-'\n",
                "]\n",
                "\n",
                "# Loading the dataset, defining the delimiter, and replacing specified missing values with NaN\n",
                "climate_data = pd.read_csv(\n",
                "    'C:/Users/auped/Desktop/IC CORREÇÕES/python 05-11/pesquisa/dadosclimaatt.csv', \n",
                "    header=None, sep=';', na_values=missing_values\n",
                ")\n",
                "\n",
                "# Assigning column names to the dataset for better interpretability\n",
                "climate_data.columns = [\n",
                "    'Max Temp (°C)', 'Min Temp (°C)', 'Avg Temp (°C)', 'Wind Speed (km/h)', \n",
                "    'Solar Radiation (cal/cm²/h)', 'Pressure (mb)', 'Humidity (%)', \n",
                "    'Precipitation (mm)', 'Day', 'Month', 'Year', 'Date', 'Date2'\n",
                "]\n",
                "\n",
                "# Data Cleaning and Type Conversion\n",
                "climate_data['Humidity (%)'] = climate_data['Humidity (%)'].str.replace(':', '.')\n",
                "climate_data['Pressure (mb)'] = climate_data['Pressure (mb)'].str.replace(',,', '.')\n",
                "\n",
                "# Converting columns to appropriate data types\n",
                "climate_data['Humidity (%)'] = climate_data['Humidity (%)'].astype(float)\n",
                "climate_data['Pressure (mb)'] = climate_data['Pressure (mb)'].astype(float)\n",
                "\n",
                "# Cleaning and converting the 'Year' column\n",
                "climate_data['Year'] = climate_data['Year'].str.replace(',,', '')\n",
                "climate_data['Year'] = climate_data['Year'].astype(int)\n",
                "\n",
                "# Storing the dataset in a list for possible further transformations\n",
                "combine = [climate_data]\n",
                "\n",
                "# Filtering out invalid pressure values (outside the typical atmospheric range)\n",
                "climate_data = climate_data[\n",
                "    (climate_data['Pressure (mb)'] >= 870) & (climate_data['Pressure (mb)'] <= 1100)\n",
                "]\n",
                "\n",
                "# Storing the updated dataset\n",
                "combine = [climate_data]\n",
                "\n",
                "# Extracting precipitation data for further analysis\n",
                "precipitation = climate_data['Precipitation (mm)']\n",
                "\n",
                "# Displaying the first five rows of the cleaned dataset\n",
                "climate_data.head()\n",
                "\n",
                "# Removing any remaining missing values\n",
                "climate_data.dropna()\n",
                "\n",
                "# Printing the count of missing values in each column\n",
                "print(climate_data.isnull().sum())\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Statistical Summary of the Dataset\n",
                "\n",
                "# This command provides key statistical metrics for numerical columns in the dataset, \n",
                "# including mean, standard deviation, minimum, and maximum values, as well as quartiles.\n",
                "climate_data.describe()\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Creating a Binary Indicator for Rain Occurrence"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Creating a Binary Indicator for Rain Occurrence\n",
                "\n",
                "# Adding a new column 'Rained?' based on precipitation data\n",
                "climate_data['Rained?'] = precipitation  \n",
                "\n",
                "# Loop to populate the new column with 0 (No Rain) and 1 (Rain)\n",
                "for climate_data in combine:    \n",
                "    climate_data.loc[climate_data['Precipitation (mm)'] == 0, 'Rained?'] = 0\n",
                "    climate_data.loc[climate_data['Precipitation (mm)'] > 0, 'Rained?'] = 1\n",
                "\n",
                "# Displaying the first five rows of the updated dataset\n",
                "climate_data.head()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Handling Missing Values (Data Imputation)\n",
                "\n",
                "# Forward Fill (ffill) method is used to propagate the last valid observation forward to fill missing values.\n",
                "# This ensures that gaps in the dataset are replaced with the most recent valid data point.\n",
                "\n",
                "climate_data['Min Temp (°C)'].fillna(method='ffill', inplace=True)   # Filling missing values with the last recorded temperature\n",
                "climate_data['Avg Temp (°C)'].fillna(method='ffill', inplace=True)   # Applying forward fill for average temperature\n",
                "climate_data['Wind Speed (km/h)'].fillna(method='ffill', inplace=True)  # Filling missing wind speed values\n",
                "climate_data['Solar Radiation (cal/cm²/h)'].fillna(method='ffill', inplace=True)  # Filling missing solar radiation values\n",
                "climate_data['Humidity (%)'].fillna(method='ffill', inplace=True)  # Filling missing humidity values\n",
                "climate_data['Precipitation (mm)'].fillna(method='ffill', inplace=True)  # Filling missing precipitation data\n",
                "climate_data['Pressure (mb)'].fillna(method='ffill', inplace=True)  # Filling missing pressure values\n",
                "climate_data['Rained?'].fillna(method='ffill', inplace=True)  # Filling missing rain indicator values\n",
                "climate_data['Max Temp (°C)'].fillna(method='ffill', inplace=True)   # Filling missing max temperature values\n",
                "\n",
                "# Checking for missing values after the imputation process\n",
                "print('\\nMissing Values in the dataset after imputation:\\n', climate_data.isnull().sum(), sep=\"\")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Splitting Data into Training (70%) and Testing (30%)\n",
                "\n",
                "start_year = 1980\n",
                "end_year = 2020\n",
                "training_start_year = 2009\n",
                "training_end_year = 2019\n",
                "testing_start_year = 1980\n",
                "testing_end_year = 2008\n",
                "\n",
                "# Creating a copy of the dataset for testing purposes\n",
                "climate_test_data = climate_data.copy()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Removing the 'Precipitation (mm)' column from the test dataset\n",
                "\n",
                "# Since precipitation is the target variable in many climate-related models, \n",
                "# we remove it from the feature set to avoid data leakage during model training.\n",
                "\n",
                "climate_test_data.drop(columns=['Precipitation (mm)'], axis=1, inplace=True)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Machine Learning Models"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Creating Training and Testing DataFrames"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Creating Training and Testing DataFrames\n",
                "\n",
                "# Filtering data for the training period\n",
                "df_train = climate_test_data[climate_test_data['Year'] >= train_start_year]\n",
                "df_train = climate_test_data[climate_test_data['Year'] <= train_end_year]\n",
                "\n",
                "# Filtering data for the testing period\n",
                "df_test = climate_test_data[climate_test_data['Year'] >= test_start_year]\n",
                "df_test = climate_test_data[climate_test_data['Year'] <= test_end_year]\n",
                "\n",
                "# Splitting features (X) and target variable (Y)\n",
                "x_train = df_train.iloc[:, 0:10]  # Selecting the first 10 columns as features\n",
                "y_train = df_train[['Rained?']]   # Target variable: Did it rain?\n",
                "\n",
                "x = df_test.iloc[:, 0:10]  # Selecting the first 10 columns as test features\n",
                "y = df_test[['Rained?']]   # Target variable for testing\n",
                "\n",
                "# Displaying the first five rows of the test feature set\n",
                "x.head()\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Model - XGBoost to Determine Whether It Rained or Not\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Creating an XGBoost Classifier instance\n",
                "xgboost_classifier = xgb.XGBClassifier()\n",
                "\n",
                "# Training the XGBoost Classifier using the training dataset\n",
                "xgb_model = xgboost_classifier.fit(x_train, y_train)\n",
                "\n",
                "# Making predictions on the training dataset\n",
                "y_pred4 = xgb_model.predict(x_train)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Importing necessary libraries\n",
                "\n",
                "# Datasets module: Provides sample datasets for testing and experimentation\n",
                "from sklearn import datasets\n",
                "\n",
                "# Splitting module: Used to divide data into training and testing subsets\n",
                "from sklearn.model_selection import train_test_split\n",
                "\n",
                "# Logistic Regression: A commonly used statistical model for binary classification\n",
                "from sklearn.linear_model import LogisticRegression\n",
                "\n",
                "# Precision-Recall Curve: Used to evaluate model performance in imbalanced datasets\n",
                "from sklearn.metrics import precision_recall_curve\n",
                "\n",
                "# Visualization library\n",
                "import matplotlib.pyplot as plt\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Score"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Evaluating the model's performance using classification metrics\n",
                "\n",
                "# Precision: Measures the proportion of correctly predicted positive instances \n",
                "# out of all instances predicted as positive (true positives / (true positives + false positives)).\n",
                "print('Precision: %.3f' % precision_score(y_train, y_pred4))\n",
                "\n",
                "# Accuracy: Represents the proportion of correctly classified instances \n",
                "# out of the total instances in the dataset.\n",
                "print('Accuracy: %.3f' % accuracy_score(y_train, y_pred4))\n",
                "\n",
                "# Recall (Sensitivity): Measures the proportion of actual positive instances \n",
                "# that were correctly identified by the model (true positives / (true positives + false negatives)).\n",
                "print('Recall: %.3f' % recall_score(y_train, y_pred4))\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Storing predicted rainfall values in a list\n",
                "predicted_rainfall = []\n",
                "for z in range(len(y_pred4)):\n",
                "    # Appending each predicted value to the list\n",
                "    predicted_rainfall.append(y_pred4[z])\n",
                "\n",
                "# Adding the predictions as a new column in the training DataFrame\n",
                "df_train['Prediction'] = predicted_rainfall\n",
                "\n",
                "# Displaying the first five rows of the updated DataFrame\n",
                "df_train.head()\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Confusion Matrices"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Model - XGBoost\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Generating the confusion matrix to evaluate classification performance\n",
                "cm = confusion_matrix(y_train, y_pred4)\n",
                "\n",
                "# Defining class labels (replace with specific labels if necessary)\n",
                "class_names = ['Negative Class', 'Positive Class']\n",
                "\n",
                "# Plotting the confusion matrix using Seaborn\n",
                "plt.figure(figsize=(8, 6))  # Adjusting figure size\n",
                "sns.set(font_scale=1.2)  # Setting font size for better readability\n",
                "\n",
                "# Creating a heatmap visualization of the confusion matrix\n",
                "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
                "\n",
                "# Setting axis labels\n",
                "plt.xlabel('Predicted Label')\n",
                "plt.ylabel('True Label')\n",
                "\n",
                "# Displaying the plot\n",
                "plt.show()\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.9"
        },
        "orig_nbformat": 4
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
